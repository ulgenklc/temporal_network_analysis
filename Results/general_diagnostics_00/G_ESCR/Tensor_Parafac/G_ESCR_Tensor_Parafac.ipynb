{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac, non_negative_parafac, tucker, Tucker\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "base_path = \"/projects/academic/smuldoon/bengieru/Community_Detection/general_diagnostics_00/\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, base_path)\n",
    "\n",
    "from helpers import *\n",
    "from Temporal_Community_Detection import temporal_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_interlayer(spikes, size, X = 0.5, omega_global = 1, percentage = 0.01, method = 'local'):\n",
    "    \n",
    "    layers ,num_neurons, t = size[0], size[1], size[2] #self.length, self.size, self.windowsize\n",
    "        \n",
    "    binned_spikes = bin_time_series(spikes, t, gaussian = False)\n",
    "    sp = np.nonzero(binned_spikes)\n",
    "        \n",
    "    count_spikes = np.zeros((layers, num_neurons))\n",
    "    interlayer = np.ones((layers-1, num_neurons))\n",
    "    \n",
    "    if method == 'local':\n",
    "        for i in range(len(sp[0])):\n",
    "            l, n, t = sp[0][i], sp[1][i], sp[2][i]\n",
    "            count_spikes[l][n] = count_spikes[l][n] + 1\n",
    "        interlayers = []\n",
    "        for i in range(layers-1):\n",
    "            zscores = zscore(np.diff(count_spikes, axis = 0)[i])\n",
    "            layerweights = []\n",
    "            for j in range(num_neurons):\n",
    "                if zscores[j] <= X: layerweights.append(percentage*omega_global)\n",
    "                else: layerweights.append(omega_global)\n",
    "            interlayers.append(layerweights)\n",
    "\n",
    "    elif method == 'global':\n",
    "        for i in range(len(sp[0])):\n",
    "            l, n, t = sp[0][i], sp[1][i], sp[2][i]\n",
    "            count_spikes[l][n] = count_spikes[l][n] + 1\n",
    "        interlayers = []\n",
    "        zscores = zscore(np.mean(np.diff(count_spikes, axis = 0)))###changed np.mean from np.sum\n",
    "        for i in range(layers-1):\n",
    "            layerweights = []\n",
    "            for j in range(num_neurons):\n",
    "                if zscores[j] <= X: layerweights.append(percentage*omega_global)\n",
    "                else: layerweights.append(omega_global)\n",
    "            interlayers.append(layerweights)\n",
    "    \n",
    "        #TODO:::  elif method == 'adjacent':\n",
    "    \n",
    "    return(interlayers)\n",
    "\n",
    "def get_normalized_outlinks(thresholded_adjacency, shape, interlayer): \n",
    "    #interlayer is the node itselves edge weight that is connected to its future self that is the maximal\n",
    "    interlayer_indices = {}\n",
    "    interlayer_weights = {}\n",
    "    length, size = shape[0], shape[1]\n",
    "    \n",
    "    for i in range(length):\n",
    "        layerweights = []\n",
    "        \n",
    "        for j in range(size):\n",
    "            maximal_neighbors = [[int(interlayer),j]]\n",
    "            \n",
    "            for nonzero in np.nonzero(thresholded_adjacency[j,:,i])[0]:\n",
    "                maximal_neighbors.append([thresholded_adjacency[j,nonzero,i], nonzero])\n",
    "                \n",
    "            weights = np.array(sorted(maximal_neighbors, reverse = True))[:,0]\n",
    "            indices = np.array(sorted(maximal_neighbors, reverse = True))[:,1]\n",
    "            \n",
    "            norm_weights = weights/np.sum(weights)\n",
    "            indices, norm_weights\n",
    "            \n",
    "            interlayer_indices['%d,%d'%(i,j)] = indices\n",
    "            interlayer_weights['%d,%d'%(i,j)] = norm_weights\n",
    "            \n",
    "    return(interlayer_indices, interlayer_weights)\n",
    "    \n",
    "def neighborhood_flow(layer, node, interlayer_indices, interlayer_weights, thresh):\n",
    "    \n",
    "    \n",
    "    length = int(min(len(interlayer_weights['%d,%d'%(layer,node)]), \n",
    "                     len(interlayer_weights['%d,%d'%(layer+1,node)]))*thresh)\n",
    "    \n",
    "    w = 1-jensenshannon(interlayer_weights['%d,%d'%(layer,node)][:length], \n",
    "                        interlayer_weights['%d,%d'%(layer+1,node)][:length])**2\n",
    "    \n",
    "    nbr = interlayer_indices['%d,%d'%(layer,node)][:length]\n",
    "    \n",
    "    return(w,nbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = base_path + 'G_ESCR/'\n",
    "\n",
    "path = data_path + 'Tensor_Parafac/'\n",
    "\n",
    "with open(data_path + 'spikes.pkl', 'rb') as handle:\n",
    "    spikes = pickle.load(handle)\n",
    "    \n",
    "with open(data_path + 'comm_size.pkl', 'rb') as handle:\n",
    "    comm_sizes = pickle.load(handle)\n",
    "    \n",
    "num_neurons = sum(comm_sizes)\n",
    "layers = 7\n",
    "\n",
    "window_size = 1000 # size, in frames, each adjacency matrix correspond to. better to be equal to bin_size \n",
    "standard_dev = 1.2 # for gaussian kernel\n",
    "k = 5 #for jittering the spikes\n",
    "pad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_spikes = bin_time_series(spikes, window_size, gaussian = True, sigma = standard_dev)\n",
    "\n",
    "adjacency_matrices = []\n",
    "for i in range(layers):\n",
    "    adjacency_matrices.append(cross_correlation_matrix(binned_spikes[i])[0])\n",
    "    \n",
    "if pad:\n",
    "    padded_adjacencies = [adjacency_matrices[0]]  + adjacency_matrices + [adjacency_matrices[-1]]\n",
    "    layers = layers + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = temporal_network(num_neurons, \n",
    "                      layers, \n",
    "                      window_size, \n",
    "                      data = 'list__adjacency', \n",
    "                      list_adjacency = padded_adjacencies, \n",
    "                      omega = 1, \n",
    "                      kind = 'ordinal')\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize = (25,15))\n",
    "TN.raster_plot(spikes, ax)\n",
    "plt.savefig(path + 'raster_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_default = np.zeros((num_neurons,num_neurons,layers))\n",
    "tensor_local = np.zeros((num_neurons,num_neurons,int((2*layers)-1)))\n",
    "tensor_nbr = np.zeros((num_neurons,num_neurons,int((2*layers)-1)))\n",
    "\n",
    "thresh = 0.2\n",
    "for i in range(layers):\n",
    "    tensor_default[:,:,i] = binarize(padded_adjacencies[i], thresh)\n",
    "X_0 = tl.tensor(tensor_default)\n",
    "\n",
    "inters = update_interlayer(spikes, [layers, num_neurons, window_size])\n",
    "for i in range(int((2*layers)-1)):\n",
    "    if i%2 == 0:\n",
    "        tensor_local[:,:,i] = binarize(padded_adjacencies[int(i/2)], thresh)\n",
    "    else:\n",
    "        tensor_local[:,:,i] = np.diag(inters[int((i-1)/2)])\n",
    "X_1 = tl.tensor(tensor_local)\n",
    "\n",
    "updated_interlayer_indices, updated_interlayer_weights = get_normalized_outlinks(tensor_default, [layers, num_neurons], 1)\n",
    "for i in range(int((2*layers)-1)):\n",
    "    if i%2 == 0:\n",
    "        tensor_nbr[:,:,i] = binarize(padded_adjacencies[int(i/2)], thresh)\n",
    "    else:\n",
    "        inter_layer = np.zeros((num_neurons,num_neurons))\n",
    "        for k in range(num_neurons):\n",
    "            w, nbr = neighborhood_flow(int(i/2), k, updated_interlayer_indices, updated_interlayer_weights, thresh)\n",
    "            if np.isnan(w):\n",
    "                w = 1.0\n",
    "            for n in nbr:\n",
    "                inter_layer[k,int(n)] = w\n",
    "                \n",
    "        tensor_nbr[:,:,i] = inter_layer\n",
    "X_2 = tl.tensor(tensor_nbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [i for i in range(2,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0 = []\n",
    "factors_0 = []\n",
    "\n",
    "weights_1 = []\n",
    "factors_1 = []\n",
    "\n",
    "weights_2 = []\n",
    "factors_2 = []\n",
    "\n",
    "for r in ranks:\n",
    "    weights_parafac_0, factors_parafac_0 = non_negative_parafac(X_0, rank = r, n_iter_max = 500, init = 'random')\n",
    "    weights_0.append(weights_parafac_0)\n",
    "    factors_0.append(factors_parafac_0)\n",
    "    \n",
    "    weights_parafac_1, factors_parafac_1 = non_negative_parafac(X_1, rank = r, n_iter_max = 500, init = 'random')\n",
    "    weights_1.append(weights_parafac_1)\n",
    "    factors_1.append(factors_parafac_1)\n",
    "    \n",
    "    weights_parafac_2, factors_parafac_2 = non_negative_parafac(X_2, rank = r, n_iter_max = 500, init = 'random')\n",
    "    weights_2.append(weights_parafac_2)\n",
    "    factors_2.append(factors_parafac_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_average = path + 'average/'\n",
    "\n",
    "os.makedirs(path_average, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_matrices_0 = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    comms_0 = np.zeros((num_neurons,layers))\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(layers):\n",
    "            comms_0[i][j] = np.argmax(((factors_0[r][0][i]+factors_0[r][1][i])/2*factors_0[r][2][j]))\n",
    "    comm_matrices_0['%d'%r] = comms_0\n",
    "    \n",
    "comm_matrices_1 = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    comms_1 = np.zeros((num_neurons,layers))\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(layers):\n",
    "            comms_1[i][j] = np.argmax(((factors_1[r][0][i]+factors_1[r][1][i])/2*factors_1[r][2][int(j*2)]))\n",
    "    comm_matrices_1['%d'%r] = comms_1\n",
    "\n",
    "comm_matrices_2 = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    comms_2 = np.zeros((num_neurons,layers))\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(layers):\n",
    "            comms_2[i][j] = np.argmax(((factors_2[r][0][i]+factors_2[r][1][i])/2*factors_2[r][2][int(j*2)]))\n",
    "    comm_matrices_2['%d'%r] = comms_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    C = np.zeros((e,layers))\n",
    "    for i in range(layers):\n",
    "        C[:,i] = np.sum(factors_0[r][0], axis = 0)*factors_0[r][2][i]\n",
    "    activity['%d'%e] = C        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(len(ranks),3,figsize = (30,10*len(ranks)))\n",
    "\n",
    "memberships_0 = {}\n",
    "memberships_1 = {}\n",
    "memberships_2 = {}\n",
    "\n",
    "for r,e in enumerate(ranks):\n",
    "    membership_0 = [[] for i in range(e)]\n",
    "    membership_1 = [[] for i in range(e)]\n",
    "    membership_2 = [[] for i in range(e)]\n",
    "    for j in range(num_neurons):\n",
    "        for k in range(layers):\n",
    "            node_id_0 = int(comm_matrices_0['%d'%r][j][k])\n",
    "            membership_0[node_id_0].append((j,k))\n",
    "            \n",
    "            node_id_1 = int(comm_matrices_1['%d'%r][j][k])\n",
    "            membership_1[node_id_1].append((j,k))\n",
    "            \n",
    "            node_id_2 = int(comm_matrices_2['%d'%r][j][k])\n",
    "            membership_2[node_id_2].append((j,k))\n",
    "            \n",
    "    memberships_0['%d'%e] = membership_0\n",
    "    memberships_1['%d'%e] = membership_1\n",
    "    memberships_2['%d'%e] = membership_2\n",
    "            \n",
    "    number_of_colors_0 = len(membership_0)\n",
    "    number_of_colors_1 = len(membership_1)\n",
    "    number_of_colors_2 = len(membership_2)\n",
    "\n",
    "    comms_0 = np.zeros((num_neurons,layers))\n",
    "    comms_1 = np.zeros((num_neurons,layers))\n",
    "    comms_2 = np.zeros((num_neurons,layers))\n",
    "\n",
    "    color_0 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors_0)]\n",
    "    color_1 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors_1)]\n",
    "    color_2 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors_2)]\n",
    "\n",
    "\n",
    "    for i, l in enumerate(membership_0):\n",
    "        for j,k in enumerate(l):\n",
    "            comms_0[k[0]][k[1]] = i\n",
    "    for i, l in enumerate(membership_1):\n",
    "        for j,k in enumerate(l):\n",
    "            comms_1[k[0]][k[1]] = i\n",
    "    for i, l in enumerate(membership_2):\n",
    "        for j,k in enumerate(l):\n",
    "            comms_2[k[0]][k[1]] = i\n",
    "\n",
    "    cmap_0 = mpl.colors.ListedColormap(color_0)\n",
    "    cmap_1 = mpl.colors.ListedColormap(color_1)\n",
    "    cmap_2 = mpl.colors.ListedColormap(color_2)\n",
    "\n",
    "    ax[r][0].imshow(comms_0, interpolation = 'none', cmap = cmap_0, aspect = 'auto', origin = 'lower')\n",
    "    ax[r][0].set_title('Ad-hoc number of communities = %d, No Adjustments'%e, fontsize = 20)\n",
    "    \n",
    "    ax[r][1].imshow(comms_1, interpolation = 'none', cmap = cmap_1, aspect = 'auto', origin = 'lower')\n",
    "    ax[r][1].set_title('Ad-hoc number of communities = %d, Local Updates'%e, fontsize = 20)\n",
    "    \n",
    "    ax[r][2].imshow(comms_2, interpolation = 'none', cmap = cmap_2, aspect = 'auto', origin = 'lower')\n",
    "    ax[r][2].set_title('Ad-hoc number of communities = %d, Neighbor Updates'%e, fontsize = 20)\n",
    "    \n",
    "plt.savefig(path_average + 'communities.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_average + \"Tensor_memberships_average_0.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(memberships_0, fp)\n",
    "with open(path_average + \"Tensor_memberships_average_1.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(memberships_1, fp)\n",
    "with open(path_average + \"Tensor_memberships_average_2.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(memberships_2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [i for i in range(2,50)]\n",
    "\n",
    "path_one_factor = path + 'one_factor/'\n",
    "\n",
    "os.makedirs(path_one_factor, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_matrices_0_A = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    comms_0 = np.zeros((num_neurons,layers))\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(layers):\n",
    "            comms_0[i][j] = np.argmax(((factors_0[r][0][i])*factors_0[r][2][j]))\n",
    "    comm_matrices_0_A['%d'%r] = comms_0\n",
    "    \n",
    "comm_matrices_1_A = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    comms_1 = np.zeros((num_neurons,layers))\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(layers):\n",
    "            comms_1[i][j] = np.argmax(((factors_1[r][0][i])*factors_1[r][2][int(j*2)]))\n",
    "    comm_matrices_1_A['%d'%r] = comms_1\n",
    "\n",
    "comm_matrices_2_A = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    comms_2 = np.zeros((num_neurons,layers))\n",
    "    for i in range(num_neurons):\n",
    "        for j in range(layers):\n",
    "            comms_2[i][j] = np.argmax(((factors_2[r][0][i])*factors_2[r][2][int(j*2)]))\n",
    "    comm_matrices_2_A['%d'%r] = comms_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = {}\n",
    "for r,e in enumerate(ranks):\n",
    "    C = np.zeros((e,layers))\n",
    "    for i in range(layers):\n",
    "        C[:,i] = np.sum(factors_0[r][0], axis = 0)*factors_0[r][2][i]\n",
    "    activity['%d'%e] = C        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(len(ranks),3,figsize = (30,10*len(ranks)))\n",
    "\n",
    "memberships_0 = {}\n",
    "memberships_1 = {}\n",
    "memberships_2 = {}\n",
    "\n",
    "for r,e in enumerate(ranks):\n",
    "    membership_0 = [[] for i in range(e)]\n",
    "    membership_1 = [[] for i in range(e)]\n",
    "    membership_2 = [[] for i in range(e)]\n",
    "    for j in range(num_neurons):\n",
    "        for k in range(layers):\n",
    "            node_id_0 = int(comm_matrices_0_A['%d'%r][j][k])\n",
    "            membership_0[node_id_0].append((j,k))\n",
    "            \n",
    "            node_id_1 = int(comm_matrices_1_A['%d'%r][j][k])\n",
    "            membership_1[node_id_1].append((j,k))\n",
    "            \n",
    "            node_id_2 = int(comm_matrices_2_A['%d'%r][j][k])\n",
    "            membership_2[node_id_2].append((j,k))\n",
    "            \n",
    "    memberships_0['%d'%e] = membership_0\n",
    "    memberships_1['%d'%e] = membership_1\n",
    "    memberships_2['%d'%e] = membership_2\n",
    "            \n",
    "    number_of_colors_0 = len(membership_0)\n",
    "    number_of_colors_1 = len(membership_1)\n",
    "    number_of_colors_2 = len(membership_2)\n",
    "\n",
    "    comms_0 = np.zeros((num_neurons,layers))\n",
    "    comms_1 = np.zeros((num_neurons,layers))\n",
    "    comms_2 = np.zeros((num_neurons,layers))\n",
    "\n",
    "    color_0 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors_0)]\n",
    "    color_1 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors_1)]\n",
    "    color_2 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors_2)]\n",
    "\n",
    "\n",
    "    for i, l in enumerate(membership_0):\n",
    "        for j,k in enumerate(l):\n",
    "            comms_0[k[0]][k[1]] = i\n",
    "    for i, l in enumerate(membership_1):\n",
    "        for j,k in enumerate(l):\n",
    "            comms_1[k[0]][k[1]] = i\n",
    "    for i, l in enumerate(membership_2):\n",
    "        for j,k in enumerate(l):\n",
    "            comms_2[k[0]][k[1]] = i\n",
    "\n",
    "    cmap_0 = mpl.colors.ListedColormap(color_0)\n",
    "    cmap_1 = mpl.colors.ListedColormap(color_1)\n",
    "    cmap_2 = mpl.colors.ListedColormap(color_2)\n",
    "\n",
    "    ax[r][0].imshow(comms_0, interpolation = 'none', cmap = cmap_0, aspect = 'auto', origin = 'lower')\n",
    "    ax[r][0].set_title('Ad-hoc number of communities = %d, No Adjustments'%e, fontsize = 20)\n",
    "    \n",
    "    ax[r][1].imshow(comms_1, interpolation = 'none', cmap = cmap_1, aspect = 'auto', origin = 'lower')\n",
    "    ax[r][1].set_title('Ad-hoc number of communities = %d, Local Updates'%e, fontsize = 20)\n",
    "    \n",
    "    ax[r][2].imshow(comms_2, interpolation = 'none', cmap = cmap_2, aspect = 'auto', origin = 'lower')\n",
    "    ax[r][2].set_title('Ad-hoc number of communities = %d, Neighbor Updates'%e, fontsize = 20)\n",
    "    \n",
    "plt.savefig(path_one_factor + 'communities.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_one_factor + \"Tensor_memberships_average_0.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(memberships_0, fp)\n",
    "with open(path_one_factor + \"Tensor_memberships_average_1.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(memberships_1, fp)\n",
    "with open(path_one_factor + \"Tensor_memberships_average_2.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(memberships_2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
