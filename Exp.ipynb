{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "import csv\n",
    "from read_roi import read_roi_file, read_roi_zip\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temporal_network:\n",
    "    def __init__(self, size, length, data, **kwargs):\n",
    "        \n",
    "        if length < 2: return('Object should be a multilayer network with at least 2 layers')\n",
    "        if size < 3: return('Layers must have at least 3 nodes')\n",
    "        \n",
    "        self.size = size # number of nodes in every layer\n",
    "        self.length = length # number of layers\n",
    "        self.nodes = [i for i in range(self.size)]\n",
    "        \n",
    "        #### data: you can go back and forth between supra adjacency and list adjacency but not to edge list\n",
    "        \n",
    "        ##         if supra__adjacency: creates the list adjacency matrix\n",
    "        ##\n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - supra_adjacency: supra adjacency matrix of shape (size*time x size*time)\n",
    "        \n",
    "        \n",
    "        ##\n",
    "        ##         if edge__list: creates undirected binary multilayer network from the egde triplets\n",
    "        ##                      given of the form (i,j,t). supra_adjacency and list_adjacency matrices \n",
    "        ##                      are automatically created. \n",
    "        ##\n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - edge_list: list of triplets e.g. [(0,2,1),(2,1,1),(0,1,2),(0,2,2)]\n",
    "        ##                       - omega: interlayer coupling strength, can be a float only for now\n",
    "        ##                       - kind: if temporal, only adjacent layers gets connected with strength 'omega'\n",
    "        ##                               if multilayer, all layers get connected w/ each other w/ strength 'omega'\n",
    "        \n",
    "        \n",
    "        ##         if list__adjacency: creates the supra adjacency matrix\n",
    "        ##              \n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - list_adjacency: list of length 'length' that contains individual adjacency\n",
    "        ##                                         matrices of each layer\n",
    "        ##                       - omega: interlayer coupling strength, can be a float only for now\n",
    "        ##                       - kind : if temporal, only adjacent layers gets connected w/ strength 'omega'\n",
    "        ##                                if multilayer, all layers get connected w/ each other w/ strength 'omega'\n",
    "        \n",
    "                    \n",
    "        if  data == 'supra__adjacency':\n",
    "            self.supra_adjacency = kwargs['supra_adjacency']\n",
    "            list_adjacency = np.zeros((self.length, self.size, self.size))\n",
    "            \n",
    "            for i in range(self.length-1):\n",
    "                list_adjacency[i][i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size] = self.supra_adjacency[i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size]\n",
    "            \n",
    "            self.list_adjacency = list_adjacency\n",
    "        \n",
    "        elif data == 'edge__list':\n",
    "            self.edgelist = kwargs['edge_list']\n",
    "            supra_adjacency = np.zeros((self.size*self.length,self.size*self.length))\n",
    "            list_adjacency = np.zeros((self.length, self.size, self.size))\n",
    "            \n",
    "            for k,e in enumerate(self.edge_list):\n",
    "                i,j,t = e[0],e[1],e[2]\n",
    "                supra_adjacency[self.size*(t-1)+i][self.size*(t-1)+j] = 1\n",
    "                supra_adjacency[self.size*(t-1)+j][self.size*(t-1)+i] = 1\n",
    "                list_adjacency[t-1][i][j] = 1\n",
    "                list_adjacency[t-1][j][i] = 1\n",
    "        \n",
    "            ##filling off-diagonal blocks\n",
    "            if kwargs['kind'] == 'temporal':\n",
    "                for n in range(self.size*(self.length-1)):\n",
    "                    supra_adjacency[n][n+self.size] = kwargs['omega']\n",
    "                    supra_adjacency[n+self.size][n] = kwargs['omega']\n",
    "                \n",
    "            elif kwargs['kind'] == 'multilayer':\n",
    "                i = 0\n",
    "                while self.length-i != 0:\n",
    "                    i = i+1\n",
    "                    for n in range(self.size*(self.length-i)):\n",
    "                        supra_adjacency[n][n+i*self.size] = kwargs['omega']\n",
    "                        supra_adjacency[n+i*self.size][n] = kwargs['omega']\n",
    "            \n",
    "            self.supra_adjacency = supra_adjacency\n",
    "            self.list_adjacency = list_adjacency\n",
    "            \n",
    "        elif data == 'list__adjacency':\n",
    "            self.list_adjacency = kwargs['list_adjacency']\n",
    "            supra_adjacency = np.zeros((self.size*self.length,self.size*self.length))\n",
    "            \n",
    "            for i in range(self.length):\n",
    "                supra_adjacency[i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size] = self.list_adjacency[i]\n",
    "            \n",
    "            ##filling off-diagonal blocks\n",
    "            if kwargs['kind'] == 'temporal':\n",
    "                for n in range(self.size*(self.length-1)):\n",
    "                    supra_adjacency[n][n+self.size] = kwargs['omega']\n",
    "                    supra_adjacency[n+self.size][n] = kwargs['omega']\n",
    "                \n",
    "            elif kwargs['kind'] == 'multilayer':\n",
    "                i = 0\n",
    "                while self.length-i != 0:\n",
    "                    i = i+1\n",
    "                    for n in range(self.size*(self.length-i)):\n",
    "                        supra_adjacency[n][n+i*self.size] = kwargs['omega']\n",
    "                        supra_adjacency[n+i*self.size][n] = kwargs['omega']\n",
    "            \n",
    "            self.supra_adjacency = supra_adjacency\n",
    "            \n",
    "    def aggragate(self, normalized = True):\n",
    "        t = self.time \n",
    "        n = self.size\n",
    "        aggragated = np.zeros((n,n))\n",
    "        \n",
    "        for i,c in enumerate(self.multi_array[:]):\n",
    "            aggragated = aggragated + c\n",
    "            \n",
    "        if normalized: return (aggragated/t)\n",
    "        else: return (aggragated)\n",
    "            \n",
    "    def modularity_matrix(self, omega, gamma):\n",
    "        N = self.size\n",
    "        T = self.time\n",
    "        B = np.zeros((N*T,N*T))\n",
    "        two_mu = 0\n",
    "        for i in range(T):\n",
    "            k = np.sum(self.multi_array[i],0)\n",
    "            two_m = np.sum(k,0)\n",
    "            two_mu = two_mu + two_m\n",
    "            B[i*N:(i+1)*N,i*N:(i+1)*N] = self.multi_array[i] - (gamma * k.T*k)/(two_m)\n",
    "        two_mu = two_mu + 2*omega*N*(T-1)\n",
    "        \n",
    "        for p in range(N*(T-1)):\n",
    "            B[p][p+N] = omega \n",
    "            B[p+N][p] = omega\n",
    "            \n",
    "        return(B)\n",
    "    def edgelist2edges(self):\n",
    "        T = self.time\n",
    "        all_edges = [[] for i in range(T)]\n",
    "        for k,e in enumerate(np.sort(self.edgelist, axis=-1)):\n",
    "            i,j,t = e[0], e[1], e[2]\n",
    "            pair = (i,j)\n",
    "            all_edges[t-1].append(pair)\n",
    "        return (all_edges)\n",
    "    \n",
    "    \n",
    "    def create_igraph(self, omega):\n",
    "        T = self.time\n",
    "        N = self.size\n",
    "        G = []\n",
    "        for i in range(T):\n",
    "            G.append(ig.Graph())\n",
    "            G[i].add_vertices(N)\n",
    "            G[i].add_edges(self.edgelist2edges()[i])\n",
    "            G[i].vs['id'] = list(range(N))\n",
    "            G[i].vs['node_size'] = 0\n",
    "            \n",
    "        G_coupling = ig.Graph.Formula('1 -- 2 -- 3 -- 4');\n",
    "        G_coupling.es['weight'] = omega; # Interslice coupling strength\n",
    "        G_coupling.vs['slice'] = [G[0], G[1], G[2], G[3]]\n",
    "        \n",
    "        layers, interslice_layer, G_full = la.time_slices_to_layers([G[0],G[1],G[2],G[3]],interslice_weight=0.1);\n",
    "        partitions = [la.CPMVertexPartition(H, node_sizes='node_size',\n",
    "                                            weights='weight', resolution_parameter=omega) for H in layers];\n",
    "        interslice_partition = la.CPMVertexPartition(interslice_layer, resolution_parameter=omega)\n",
    "                                                     \n",
    "        return(partitions, interslice_partition)\n",
    "    \n",
    "    def leiden(self):\n",
    "        optimiser = la.Optimiser()\n",
    "        diff = optimiser.optimise_partition_multiplex(self.create_igraph_try(omega=0)[0] + [self.create_igraph_try(omega=0)[1]])\n",
    "\n",
    "        return(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_corr(x,y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    \n",
    "    x_cov_std = np.nanmax(np.sqrt(np.correlate(x - x_mean, x - x_mean, 'full')))\n",
    "    y_cov_std = np.nanmax(np.sqrt(np.correlate(y - y_mean, y - y_mean, 'full')))\n",
    "\n",
    "    normalization = x_cov_std * y_cov_std\n",
    "        \n",
    "\n",
    "    unnormalized_correlation = np.correlate(x - x_mean, y - y_mean, 'full')\n",
    "    \n",
    "    corr_array = unnormalized_correlation/normalization\n",
    "\n",
    "    return(corr_array)\n",
    "\n",
    "def max_norm_cross_corr(x1, x2):\n",
    "    \n",
    "    correlation= normalized_cross_corr(x1, x2)\n",
    "    \n",
    "    lag = abs(correlation).argmax() - len(x1)+1\n",
    "    \n",
    "    max_corr = max(abs(correlation))\n",
    "    \n",
    "    return(max_corr, lag)\n",
    "\n",
    "def cross_correlation_matrix(data):\n",
    "    #input: n x t matrix where n is the number of rois and t is the duration of the time series\n",
    "    #return: n x n cross correlation matrix and lag matrix\n",
    "    n, t = data.shape\n",
    "    X = np.zeros((n,n))\n",
    "    lag = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            X[i][j],lag[i][j] = max_norm_cross_corr(data[i,:],data[j,:])\n",
    "    X[np.isnan(X)] = 0\n",
    "    lag[np.isnan(lag)] = 0\n",
    "    \n",
    "    X = X + X.T\n",
    "    lag = lag + lag.T\n",
    "    return(X,lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, output, subject, roi, subject_roi):\n",
    "    trace=open( path + output + subject + \"_trace.csv\", \"r\")\n",
    "    spike=open( path + output + subject + \"_spikes_complexity.csv\", \"r\")\n",
    "    reader_trace = csv.reader(trace)\n",
    "    reader_spike = csv.reader(spike)\n",
    "    n = read_roi(path, roi, subject_roi)\n",
    "    traces = np.zeros((n,8000)) # roi x time\n",
    "    spikes = np.zeros((n,8000)) # roi x time\n",
    "    #row_count = sum(1 for row in reader)\n",
    "    \n",
    "    for i,line in enumerate(reader_trace):\n",
    "        for j in range(len(line)):\n",
    "            traces[i][j]=line[j]\n",
    "    for i,line in enumerate(reader_spike):\n",
    "        for j in range(len(line)):\n",
    "            spikes[i][j]=line[j]\n",
    "    return(traces, spikes)\n",
    "            \n",
    "def read_roi(path, roi, subject_roi):\n",
    "    roi = read_roi_zip(glob(path+roi+subject_roi +'.zip')[0])\n",
    "    n = len(roi)\n",
    "    for i, R in enumerate(roi):\n",
    "        x = roi[R]['x']\n",
    "        y = roi[R]['y']\n",
    "    return(n)\n",
    "\n",
    "def bin_time_series(array, binsize):\n",
    "    binned_spikes = []\n",
    "    for i in range(len(array)):\n",
    "        binned_spikes.append(array[i].reshape(binsize,int(8000/binsize)))\n",
    "    return(np.array(binned_spikes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/bengieru/MLN/data/' ## base path\n",
    "output = 'Johan_Clean_Traces_Features_and_Spikes' #spikes and traces file\n",
    "roi = 'sarah_ROI' #roi file\n",
    "subject_roi = '/mouse_1_session_1_baseline' #subject\n",
    "subject = '/m_1_session_1_baseline'# subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 500 ## binning the time into chunks of\n",
    "n = read_roi(path, roi, subject_roi) ## number of rois\n",
    "t = int(8000/time) ## number of layers\n",
    "traces, spikes = read_csv(path, output, subject, roi, subject_roi) #read the networks\n",
    "binned_spikes = bin_time_series(spikes, time) # bin the spikes into fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "##create cross-correlation matrices that are the adjacency matrices of the network at each layer\n",
    "adjacency_matrices=[]\n",
    "for i in range(binned_spikes.shape[2]):\n",
    "    adjacency_matrices.append(cross_correlation_matrix(binned_spikes[:,:,i])[0]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = temporal_network(n, t, data = 'list__adjacency', list_adjacency = adjacency_matrices, omega = 1, kind= 'temporal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.27184405, 0.36955297, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.27184405, 0.        , 0.73283274, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36955297, 0.73283274, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.57997323],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.57997323, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN.supra_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
