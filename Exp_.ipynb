{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from math import floor\n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "import csv\n",
    "from read_roi import read_roi_file, read_roi_zip\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temporal_network:#object for creating node-aligned(every node exists every layer)\n",
    "                       #with diagonal coupling(inter-layer edges exist only between node to itself)\n",
    "        \n",
    "    ##################################\n",
    "    # TODO: extend omega(scalar) for vector and matrix\n",
    "    ##################################\n",
    "        \n",
    "    def __init__(self, size, length, data, **kwargs):\n",
    "        \n",
    "        if length < 1: return('Object should be a multilayer network with at least 2 layers')\n",
    "        if size < 3: return('Layers must have at least 3 nodes')\n",
    "        \n",
    "        self.size = size # number of nodes in every layer\n",
    "        self.length = length # number of layers\n",
    "        self.nodes = [i for i in range(self.size)]\n",
    "        \n",
    "        #### data: supra__adjacency, list_adjacency, edge_list\n",
    "        \n",
    "        ##         if supra__adjacency: creates the list adjacency matrix\n",
    "        ##\n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - supra_adjacency: supra adjacency matrix of shape (size*time x size*time)\n",
    "        \n",
    "        \n",
    "        ##\n",
    "        ##         if edge__list: creates directed weighted multilayer network from the egde quadraplets\n",
    "        ##                      given of the form (i,j,w,t). supra_adjacency and list_adjacency matrices \n",
    "        ##                      are automatically created. \n",
    "        ##\n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - edge_list: list of quadreplets e.g. [(0,2,w1,1),(2,1,w2,1),(0,1,w3,2),(0,2,w4,2)]\n",
    "        ##                       - omega: interlayer coupling strength, can be a float only for now\n",
    "        ##                       - kind: if ordinal, only adjacent layers gets connected with strength scalar 'omega'\n",
    "        ##                               if cardinal, all layers get connected w/ each other w/ strength scalar 'omega'\n",
    "        \n",
    "        \n",
    "        ##         if list__adjacency: creates the supra adjacency matrix from given list of adjacency matrices\n",
    "        ##                             of monolayer networks\n",
    "        ##                             TODO:add a warning to check if the adjacency matrices are node-aligned\n",
    "        ##                      \n",
    "        ##              \n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - list_adjacency: list of length 'length' that contains individual adjacency\n",
    "        ##                                         matrices of each layer that are numpy arrays\n",
    "        ##                       - omega: interlayer coupling strength, can be a float only for now\n",
    "        ##                       - kind : if ordinal, only adjacent layers gets connected w/ strength scalar'omega'\n",
    "        ##                                if cardinal, all layers get connected w/ each other w/ strength scalar'omega'\n",
    "        ##\n",
    "        ####\n",
    "                    \n",
    "        if  data == 'supra__adjacency':\n",
    "            self.supra_adjacency = kwargs['supra_adjacency']\n",
    "            list_adjacency = [ [] for i in range(length) ]\n",
    "            \n",
    "            for i in range(self.length):\n",
    "                list_adjacency[i] = self.supra_adjacency[i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size]\n",
    "            \n",
    "            self.list_adjacency = list_adjacency\n",
    "            \n",
    "            edge_list = []\n",
    "            for i in range(self.length):\n",
    "                A = self.list_adjacency[i]\n",
    "                firing = np.transpose(np.nonzero(A))\n",
    "                for j,m in enumerate(firing):\n",
    "                    quadreplet =(m[0],m[1],A[m[0],m[1]],i)\n",
    "                    edge_list.append(quadreplet)\n",
    "            self.edgelist = edge_list\n",
    "                \n",
    "        \n",
    "        elif data == 'edge__list':\n",
    "            self.edgelist = kwargs['edge_list']\n",
    "            supra_adjacency = np.zeros((self.size*self.length,self.size*self.length))\n",
    "            list_adjacency = [ [] for i in range(self.length) ]\n",
    "            for q in range(self.length):\n",
    "                list_adjacency[q]=np.zeros((self.size,self.size))\n",
    "            \n",
    "            for k,e in enumerate(self.edgelist):\n",
    "                i,j,w,t = e[0], e[1], e[2],e[3]\n",
    "                supra_adjacency[self.size*(t)+i][self.size*(t)+j] = w\n",
    "                list_adjacency[t][i][j] = w\n",
    "\n",
    "        \n",
    "            ##filling off-diagonal blocks\n",
    "            if kwargs['kind'] == 'ordinal':\n",
    "                for n in range(self.size*(self.length-1)):\n",
    "                    supra_adjacency[n][n+self.size] = kwargs['omega']\n",
    "                    supra_adjacency[n+self.size][n] = kwargs['omega']\n",
    "                \n",
    "            elif kwargs['kind'] == 'cardinal':\n",
    "                i = 0\n",
    "                while self.length-i != 0:\n",
    "                    i = i+1\n",
    "                    for n in range(self.size*(self.length-i)):\n",
    "                        supra_adjacency[n][n+i*self.size] = kwargs['omega']\n",
    "                        supra_adjacency[n+i*self.size][n] = kwargs['omega']\n",
    "            \n",
    "            self.supra_adjacency = supra_adjacency\n",
    "            self.list_adjacency = list_adjacency\n",
    "            \n",
    "        elif data == 'list__adjacency':\n",
    "            self.list_adjacency = kwargs['list_adjacency']\n",
    "            supra_adjacency = np.zeros((self.size*self.length,self.size*self.length))\n",
    "            \n",
    "            for i in range(self.length):\n",
    "                supra_adjacency[i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size] = self.list_adjacency[i]\n",
    "            \n",
    "            ##filling off-diagonal blocks\n",
    "            if kwargs['kind'] == 'ordinal':\n",
    "                for n in range(self.size*(self.length-1)):\n",
    "                    supra_adjacency[n][n+self.size] = kwargs['omega']\n",
    "                    supra_adjacency[n+self.size][n] = kwargs['omega']\n",
    "                \n",
    "            elif kwargs['kind'] == 'cardinal':\n",
    "                i = 0\n",
    "                while self.length-i != 0:\n",
    "                    i = i+1\n",
    "                    for n in range(self.size*(self.length-i)):\n",
    "                        supra_adjacency[n][n+i*self.size] = kwargs['omega']\n",
    "                        supra_adjacency[n+i*self.size][n] = kwargs['omega']\n",
    "            \n",
    "            self.supra_adjacency = supra_adjacency\n",
    "            \n",
    "            edge_list = []\n",
    "            for i in range(self.length):\n",
    "                A = self.list_adjacency[i]\n",
    "                firing = np.transpose(np.nonzero(A))\n",
    "                for j,m in enumerate(firing):\n",
    "                    quadreplet =(m[0],m[1],A[m[0],m[1]],i)\n",
    "                    edge_list.append(quadreplet)\n",
    "            self.edgelist = edge_list\n",
    "            \n",
    "    def aggragate(self, normalized = True):\n",
    "        t = self.length\n",
    "        n = self.size\n",
    "        aggragated = np.zeros((n,n))\n",
    "        \n",
    "        for i,c in enumerate(self.list_adjacency):\n",
    "            aggragated = aggragated + c\n",
    "            \n",
    "        if normalized: return (aggragated/t)\n",
    "        else: return (aggragated)\n",
    "            \n",
    "    def modularity_matrix(self, omega, gamma):##TODO: fix modularity matrix\n",
    "        N = self.size\n",
    "        T = self.length\n",
    "        B = np.zeros((N*T,N*T))\n",
    "        two_mu = 0\n",
    "        for i in range(T):\n",
    "            k = np.sum(self.multi_array[i],0)\n",
    "            two_m = np.sum(k,0)\n",
    "            two_mu = two_mu + two_m\n",
    "            B[i*N:(i+1)*N,i*N:(i+1)*N] = self.multi_array[i] - (gamma * k.T*k)/(two_m)\n",
    "        two_mu = two_mu + 2*omega*N*(T-1)\n",
    "        \n",
    "        for p in range(N*(T-1)):\n",
    "            B[p][p+N] = omega \n",
    "            B[p+N][p] = omega\n",
    "            \n",
    "        return(B)\n",
    "    \n",
    "    def edgelist2edges(self):\n",
    "        T = self.length\n",
    "        all_edges = [[] for i in range(T)]\n",
    "        weights = []\n",
    "        dtype = [('row',int),('column',int),('weight',float),('layer',int)]\n",
    "        for k,e in enumerate(np.sort(np.array(self.edgelist, dtype=dtype),order='layer')):\n",
    "            i,j,w,t = e[0], e[1], e[2],e[3]\n",
    "            pair = (i,j)\n",
    "            all_edges[t].append(pair)\n",
    "            weights.append(w)\n",
    "        return (all_edges, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_corr(x,y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    \n",
    "    x_cov_std = np.nanmax(np.sqrt(np.correlate(x - x_mean, x - x_mean, 'full')))\n",
    "    y_cov_std = np.nanmax(np.sqrt(np.correlate(y - y_mean, y - y_mean, 'full')))\n",
    "\n",
    "    normalization = x_cov_std * y_cov_std\n",
    "        \n",
    "\n",
    "    unnormalized_correlation = np.correlate(x - x_mean, y - y_mean, 'full')\n",
    "    \n",
    "    corr_array = unnormalized_correlation/normalization\n",
    "\n",
    "    return(corr_array)\n",
    "\n",
    "def max_norm_cross_corr(x1, x2):\n",
    "    \n",
    "    correlation= normalized_cross_corr(x1, x2)\n",
    "    \n",
    "    lag = abs(correlation).argmax() - len(x1)+1\n",
    "    \n",
    "    max_corr = max(abs(correlation))\n",
    "    \n",
    "    return(max_corr, lag)\n",
    "\n",
    "def cross_correlation_matrix(data):\n",
    "    #input: n x t matrix where n is the number of rois and t is the duration of the time series\n",
    "    #return: n x n symmetric cross correlation matrix, nxn uppertriangular cross correlation matrix and lag matrix\n",
    "    n, t = data.shape\n",
    "    X = np.zeros((n,n))\n",
    "    lag = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            X[i][j],lag[i][j] = max_norm_cross_corr(data[i,:],data[j,:])\n",
    "    X[np.isnan(X)] = 0\n",
    "    lag[np.isnan(lag)] = 0\n",
    "    \n",
    "    X_full = X + X.T\n",
    "    lag = lag + lag.T\n",
    "    return(X_full, X, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path, output, subject, roi, subject_roi):\n",
    "    trace=open( path + output + subject + \"_trace.csv\", \"r\")\n",
    "    spike=open( path + output + subject + \"_spikes_complexity.csv\", \"r\")\n",
    "    reader_trace = csv.reader(trace)\n",
    "    reader_spike = csv.reader(spike)\n",
    "    n = read_roi(path, roi, subject_roi)\n",
    "    traces = np.zeros((n,8000)) # roi x time\n",
    "    spikes = np.zeros((n,8000)) # roi x time\n",
    "    #row_count = sum(1 for row in reader)\n",
    "    \n",
    "    for i,line in enumerate(reader_trace):\n",
    "        for j in range(len(line)):\n",
    "            traces[i][j]=line[j]\n",
    "    for i,line in enumerate(reader_spike):\n",
    "        for j in range(len(line)):\n",
    "            spikes[i][j]=line[j]\n",
    "    return(traces, spikes)\n",
    "            \n",
    "def read_roi(path, roi, subject_roi):\n",
    "    roi = read_roi_zip(glob(path+roi+subject_roi +'.zip')[0])\n",
    "    n = len(roi)\n",
    "    for i, R in enumerate(roi):\n",
    "        x = roi[R]['x']\n",
    "        y = roi[R]['y']\n",
    "    return(n)\n",
    "\n",
    "def bin_time_series(array, binsize, gaussian=True, **kwargs):\n",
    "    binned_spikes = []\n",
    "    for i in range(len(array)):\n",
    "        A = array[i].reshape(binsize,int(8000/binsize))\n",
    "        if gaussian:\n",
    "            A = gaussian_filter(A,kwargs['sigma'])\n",
    "        binned_spikes.append(A)\n",
    "    return(np.array(binned_spikes))\n",
    "\n",
    "def gaussian_filter(array,sigma):\n",
    "    #sigma=0.25==gaussian kernel with length 3\n",
    "    #sigma=0.5==gaussian kernel with length 5\n",
    "    #sigma=1==gaussian kernel with length 9\n",
    "    return(gaussian_filter1d(array,sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/bengieru/MLN/data/' ## base path\n",
    "output = 'Johan_Clean_Traces_Features_and_Spikes' #spikes and traces file\n",
    "roi = 'sarah_ROI' #roi file\n",
    "subject_roi = '/mouse_1_session_1_baseline' #subject\n",
    "subject = '/m_1_session_1_baseline'# subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 500 ## binning the time into chunks of\n",
    "n = read_roi(path, roi, subject_roi) ## number of rois\n",
    "t = int(8000/time) ## number of layers\n",
    "traces, spikes = read_csv(path, output, subject, roi, subject_roi) #read the networks\n",
    "binned_spikes = bin_time_series(spikes, time, gaussian = True, sigma=0.25) # bin the spikes into fixed length and apply gaussian kernel of length 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in sqrt\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in true_divide\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "##create cross-correlation matrices that are the adjacency matrices of the network at each layer\n",
    "adjacency_matrices = []\n",
    "for i in range(binned_spikes.shape[2]):\n",
    "    adjacency_matrices.append(cross_correlation_matrix(binned_spikes[:,:,i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TN- directed full temporal network object\n",
    "TN = temporal_network(n, t, data = 'list__adjacency', list_adjacency = adjacency_matrices, omega = 1, kind= 'ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
