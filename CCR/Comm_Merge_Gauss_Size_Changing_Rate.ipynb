{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from math import floor\n",
    "import leidenalg as la\n",
    "import igraph as ig\n",
    "from elephant.spike_train_generation import homogeneous_poisson_process\n",
    "import elephant.conversion as conv\n",
    "import neo as n\n",
    "import quantities as pq\n",
    "from quantities import Hz, s, ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temporal_network:#object for creating node-aligned(every node exists every layer)\n",
    "                       #with diagonal coupling(inter-layer edges exist only between node to itself)\n",
    "        \n",
    "    ##################################\n",
    "    # TODO: extend omega(scalar) for vector and matrix\n",
    "    ##################################\n",
    "        \n",
    "    def __init__(self, size, length, window_size, data, **kwargs):\n",
    "        \n",
    "        if length < 1: raise ValueError('Object should be a multilayer network with at least 2 layers')\n",
    "        if size < 3: raise ValueError('Layers must have at least 3 nodes')\n",
    "        \n",
    "        self.size = size # number of nodes in every layer\n",
    "        self.length = length # number of layers\n",
    "        self.nodes = [i for i in range(self.size)]\n",
    "        self.windowsize = window_size\n",
    "        \n",
    "        #### data: supra__adjacency, list_adjacency, edge_list\n",
    "        \n",
    "        ##         if supra__adjacency: creates the list adjacency matrix\n",
    "        ##\n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - supra_adjacency: supra adjacency matrix of shape (size*time x size*time)\n",
    "        \n",
    "        \n",
    "        ##\n",
    "        ##         if edge__list: creates directed weighted multilayer network from the egde quadraplets\n",
    "        ##                      given of the form (i,j,w,t). supra_adjacency and list_adjacency matrices \n",
    "        ##                      are automatically created. Caveat: if you use edge_list only firing neurons are going\n",
    "        ##                      to be taken ito consideration.\n",
    "        ##\n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - edge_list: list of quadreplets e.g. [(0,2,w1,1),(2,1,w2,1),(0,1,w3,2),(0,2,w4,2)]\n",
    "        ##                       - omega: interlayer coupling strength, can be a float only for now\n",
    "        ##                       - kind: if ordinal, only adjacent layers gets connected with strength scalar 'omega'\n",
    "        ##                               if cardinal, all layers get connected w/ each other w/ strength scalar 'omega'\n",
    "        \n",
    "        \n",
    "        ##         if list__adjacency: creates the supra adjacency matrix from given list of adjacency matrices\n",
    "        ##                             of monolayer networks\n",
    "        ##                             TODO:add a warning to check if the adjacency matrices are node-aligned\n",
    "        ##                      \n",
    "        ##              \n",
    "        ##                     --- additional arguments ---\n",
    "        ##                       - list_adjacency: list of length 'length' that contains individual adjacency\n",
    "        ##                                         matrices of each layer that are numpy arrays\n",
    "        ##                       - omega: interlayer coupling strength, can be a float only for now\n",
    "        ##                       - kind : if ordinal, only adjacent layers gets connected w/ strength scalar'omega'\n",
    "        ##                                if cardinal, all layers get connected w/ each other w/ strength scalar'omega'\n",
    "        ##\n",
    "        ####\n",
    "                    \n",
    "        if  data == 'supra__adjacency':\n",
    "            self.supra_adjacency = kwargs['supra_adjacency']\n",
    "            list_adjacency = [ [] for i in range(length) ]\n",
    "            \n",
    "            for i in range(self.length):\n",
    "                list_adjacency[i] = self.supra_adjacency[i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size]\n",
    "            \n",
    "            self.list_adjacency = list_adjacency\n",
    "            \n",
    "            edge_list = []\n",
    "            for i in range(self.length):\n",
    "                A = self.list_adjacency[i]\n",
    "                firing = np.transpose(np.nonzero(A))\n",
    "                for j,m in enumerate(firing):\n",
    "                    quadreplet =(m[0],m[1],A[m[0],m[1]],i)\n",
    "                    edge_list.append(quadreplet)\n",
    "            self.edgelist = edge_list\n",
    "                \n",
    "        \n",
    "        elif data == 'edge__list':\n",
    "            self.edgelist = kwargs['edge_list']\n",
    "            supra_adjacency = np.zeros((self.size*self.length,self.size*self.length))\n",
    "            list_adjacency = [ [] for i in range(self.length) ]\n",
    "            for q in range(self.length):\n",
    "                list_adjacency[q]=np.zeros((self.size,self.size))\n",
    "            \n",
    "            for k,e in enumerate(self.edgelist):\n",
    "                i,j,w,t = e[0], e[1], e[2],e[3]\n",
    "                supra_adjacency[self.size*(t)+i][self.size*(t)+j] = w\n",
    "                list_adjacency[t][i][j] = w\n",
    "\n",
    "        \n",
    "            ##filling off-diagonal blocks\n",
    "            if kwargs['kind'] == 'ordinal':\n",
    "                for n in range(self.size*(self.length-1)):\n",
    "                    supra_adjacency[n][n+self.size] = kwargs['omega']\n",
    "                    supra_adjacency[n+self.size][n] = kwargs['omega']\n",
    "                \n",
    "            elif kwargs['kind'] == 'cardinal':\n",
    "                i = 0\n",
    "                while self.length-i != 0:\n",
    "                    i = i+1\n",
    "                    for n in range(self.size*(self.length-i)):\n",
    "                        supra_adjacency[n][n+i*self.size] = kwargs['omega']\n",
    "                        supra_adjacency[n+i*self.size][n] = kwargs['omega']\n",
    "            \n",
    "            self.supra_adjacency = supra_adjacency\n",
    "            self.list_adjacency = list_adjacency\n",
    "            \n",
    "        elif data == 'list__adjacency':\n",
    "            self.list_adjacency = kwargs['list_adjacency']\n",
    "            supra_adjacency = np.zeros((self.size*self.length,self.size*self.length))\n",
    "            \n",
    "            for i in range(self.length):\n",
    "                supra_adjacency[i*self.size:(i+1)*self.size,i*self.size:(i+1)*self.size] = self.list_adjacency[i]\n",
    "            \n",
    "            ##filling off-diagonal blocks\n",
    "            if kwargs['kind'] == 'ordinal':\n",
    "                for n in range(self.size*(self.length-1)):\n",
    "                    supra_adjacency[n][n+self.size] = kwargs['omega']\n",
    "                    supra_adjacency[n+self.size][n] = kwargs['omega']\n",
    "                \n",
    "            elif kwargs['kind'] == 'cardinal':\n",
    "                i = 0\n",
    "                while self.length-i != 0:\n",
    "                    i = i+1\n",
    "                    for n in range(self.size*(self.length-i)):\n",
    "                        supra_adjacency[n][n+i*self.size] = kwargs['omega']\n",
    "                        supra_adjacency[n+i*self.size][n] = kwargs['omega']\n",
    "            \n",
    "            self.supra_adjacency = supra_adjacency\n",
    "            \n",
    "            edge_list = []\n",
    "            for i in range(self.length):\n",
    "                A = self.list_adjacency[i]\n",
    "                firing = np.transpose(np.nonzero(A))\n",
    "                for j,m in enumerate(firing):\n",
    "                    quadreplet =(m[0],m[1],A[m[0],m[1]],i)\n",
    "                    edge_list.append(quadreplet)\n",
    "            self.edgelist = edge_list\n",
    "            \n",
    "    def aggragate(self, normalized = True):\n",
    "        t = self.length\n",
    "        n = self.size\n",
    "        aggragated = np.zeros((n,n))\n",
    "        \n",
    "        for i,c in enumerate(self.list_adjacency):\n",
    "            aggragated = aggragated + c\n",
    "            \n",
    "        if normalized: return (aggragated/t)\n",
    "        else: return (aggragated)\n",
    "            \n",
    "    def modularity_matrix(self, omega, gamma):##TODO: fix modularity matrix\n",
    "        N = self.size\n",
    "        T = self.length\n",
    "        B = np.zeros((N*T,N*T))\n",
    "        two_mu = 0\n",
    "        for i in range(T):\n",
    "            k = np.sum(self.multi_array[i],0)\n",
    "            two_m = np.sum(k,0)\n",
    "            two_mu = two_mu + two_m\n",
    "            B[i*N:(i+1)*N,i*N:(i+1)*N] = self.multi_array[i] - (gamma * k.T*k)/(two_m)\n",
    "        two_mu = two_mu + 2*omega*N*(T-1)\n",
    "        \n",
    "        for p in range(N*(T-1)):\n",
    "            B[p][p+N] = omega \n",
    "            B[p+N][p] = omega\n",
    "            \n",
    "        return(B)\n",
    "    \n",
    "    def binarize(self, array):\n",
    "        n,t = array.shape\n",
    "        binary_spikes = np.zeros(array.shape)\n",
    "        for i in range(n):\n",
    "            for j in range(t):\n",
    "                if array[i][j] == 0: pass\n",
    "                else: binary_spikes[i][j] = 1\n",
    "        return(binary_spikes)\n",
    "    \n",
    "    def bin_time_series(self, array, gaussian = True, **kwargs):\n",
    "        #input: nxt matrix \n",
    "        #returns: binned time series i.e. l x n x binsize\n",
    "        \n",
    "        binsize = self.windowsize\n",
    "        n = array.shape[0] # number of neurons\n",
    "        totalsize = array.shape[1] # total duration of spikes\n",
    "        gauss_array = np.zeros((n,totalsize))\n",
    "        l = int(totalsize/binsize) # number of resulting layers\n",
    "        \n",
    "        if gaussian:\n",
    "            for i in range(n):\n",
    "                gauss_array[i] = gaussian_filter(array[i],kwargs['sigma'])\n",
    "        else: gauss_array= array\n",
    "            \n",
    "        A = np.zeros((l,n,binsize))\n",
    "        for i in range(l):\n",
    "            A[i] = gauss_array[:,i*binsize:(i+1)*binsize]\n",
    "        return(A)\n",
    "    \n",
    "    def edgelist2edges(self):# helper to create igraphs\n",
    "        T = self.length\n",
    "        all_edges = [[] for i in range(T)]\n",
    "        all_weights = [[] for i in range(T)]\n",
    "        dtype = [('row',int),('column',int),('weight',float),('layer',int)]\n",
    "        for k,e in enumerate(np.sort(np.array(self.edgelist, dtype=dtype),order='layer')):\n",
    "            i,j,w,t = e[0], e[1], e[2],e[3]\n",
    "            pair = (i,j)\n",
    "            all_edges[t].append(pair)\n",
    "            all_weights[t].append(w)\n",
    "        return (all_edges, all_weights)\n",
    "    \n",
    "    def neighbors(self, node_id, layer):\n",
    "        \n",
    "        if node_id > self.size: return('Invalid node ID')\n",
    "        if layer > self.length: return('Invalid layer')\n",
    "        neighbors = []\n",
    "        \n",
    "        for k,e in enumerate(self.edgelist):\n",
    "            i,j,w,t = e[0],e[1],e[2],e[3]\n",
    "            if t != layer:pass\n",
    "            else:\n",
    "                if i != node_id:pass\n",
    "                else:neighbors.append(j)\n",
    "                    \n",
    "        return(neighbors)\n",
    "    \n",
    "    def average_degree(self,layer):\n",
    "        \n",
    "        average_degree = 0\n",
    "        \n",
    "        for i in range(self.size):\n",
    "            average_degree = average_degree + len(self.neighbors(i,layer))\n",
    "        \n",
    "        return(average_degree/(2*self.size))\n",
    "    \n",
    "    def create_igraph(self):\n",
    "        T = self.length\n",
    "        N = self.size\n",
    "        G = []\n",
    "        edges = self.edgelist2edges()[0]\n",
    "        weights = self.edgelist2edges()[1]\n",
    "        for i in range(T):\n",
    "            G.append(ig.Graph())\n",
    "            G[i].add_vertices(N)\n",
    "            G[i].add_edges(edges[i])\n",
    "            G[i].es['weight'] = weights[i]\n",
    "            G[i].vs['id'] = list(range(N))\n",
    "            G[i].vs['node_size'] = 0\n",
    "        return(G)\n",
    "\n",
    "    \n",
    "    def leiden(self, G, interslice, resolution):\n",
    "        \n",
    "        layers, interslice_layer, G_full = la.time_slices_to_layers(G, interslice_weight = interslice)\n",
    "        \n",
    "        partitions = [la.RBConfigurationVertexPartition(H, \n",
    "                                            weights = 'weight', \n",
    "                                            resolution_parameter = resolution) for H in layers]\n",
    "        \n",
    "        interslice_partition = la.RBConfigurationVertexPartition(interslice_layer, \n",
    "                                                                 weights = 'weight',\n",
    "                                                                 resolution_parameter = 0)\n",
    "                                                     \n",
    "        optimiser = la.Optimiser()\n",
    "        \n",
    "        diff = optimiser.optimise_partition_multiplex(partitions + [interslice_partition])\n",
    "\n",
    "        return(partitions, interslice_partition)\n",
    "    \n",
    "    def membership(self, interslice_partition): ## returns the community assignments from the leiden algorithm as\n",
    "        ##                                       tuple (n,t) n is the node id t is the layer that node is in\n",
    "        n = self.size\n",
    "        membership = [[] for i in range(interslice_partition._len)]\n",
    "        for i,m in enumerate(interslice_partition._membership):\n",
    "            time = floor(i/n)\n",
    "            node_id = i%n\n",
    "            membership[m].append((node_id,time))\n",
    "        return(membership, len(membership))\n",
    "    \n",
    "    def community(self, membership, ax):\n",
    "        n = self.size\n",
    "        t = self.length\n",
    "        number_of_colors = len(membership)\n",
    "\n",
    "\n",
    "        comms = np.zeros((n,t))\n",
    "\n",
    "        color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(number_of_colors)]\n",
    "\n",
    "        for i, l in enumerate(membership):\n",
    "            for j,k in enumerate(l):\n",
    "                comms[k[0]][k[1]] = i\n",
    "\n",
    "        cmap = mpl.colors.ListedColormap(color)\n",
    "\n",
    "        #fig,ax = plt.subplots(1,1,figsize=(7,5))\n",
    "        ax.imshow(comms, interpolation = 'none', cmap = cmap, aspect = 'auto', origin = 'lower', extent = [-0.5,t-0.5,-0.5,n-0.5])\n",
    "        ax.set_xticks([i for i in range(t)])\n",
    "        ax.set_yticks([i*10 for i in range(int(n/10)+1)])\n",
    "        ax.tick_params(axis = 'both', labelsize = 25)\n",
    "        ax.set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax.set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax.set_title('Community Assignments with %d Communities' %len(color), fontsize = 20)\n",
    "        return(comms, color)\n",
    "    \n",
    "    def raster_plot(self, spikes, ax, color = None, **kwargs):#plots the raster plot of the spike activity on a \n",
    "        # given axis 'comm_assignment' and 'color' arguments are the outputs of the function 'community' \n",
    "        # and they display the community assignment of the spiking activity if provided. if not, raster \n",
    "        # ais going to be plotted blue\n",
    "        binsize = self.windowsize\n",
    "        binarized_spikes = self.binarize(spikes)\n",
    "        binned_spikes = self.bin_time_series(binarized_spikes, gaussian = False)\n",
    "        l,n,t = binned_spikes.shape\n",
    "                    \n",
    "        sp = np.nonzero(binned_spikes)\n",
    "        \n",
    "        if color is None: \n",
    "            col = [0]*l\n",
    "            clr = [col for i in range(n)]\n",
    "            color = ['#0000ff']\n",
    "        else: clr = kwargs['comm_assignment']\n",
    "        \n",
    "        cmap = mpl.colors.ListedColormap(color)\n",
    "        \n",
    "        for i in range(len(sp[0])):\n",
    "            ax.scatter(sp[0][i]*binsize+sp[2][i],  sp[1][i], \n",
    "                       s = 5, \n",
    "                       c = color[int(clr[sp[1][i]][sp[0][i]])], \n",
    "                       marker = 'x', \n",
    "                       figure = fig, \n",
    "                       cmap = cmap)\n",
    "            \n",
    "        ax.set_title('Raster Plot', fontsize = 20)\n",
    "        ax.set_xlabel('Time (Frames)', fontsize = 25)\n",
    "        ax.set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax.set_xticks([t*i for i in range(l+1)])\n",
    "        ax.set_yticks([5*i for i in range(int(n/5)+1)]+[n])\n",
    "        ax.tick_params(axis = 'x', labelsize = 13)\n",
    "        ax.tick_params(axis = 'y', labelsize = 18)\n",
    "    \n",
    "    def trajectories(self, thresh = 0.9, node_id = None, community = None, edge_color = True, pv = None):\n",
    "        #function graphing the edge trajcetories of the temporal\n",
    "        ## network. Tresh is for thresholding the paths that are strongere than the given value.\n",
    "        ## if node_id is None, function is going to graph all of the nodes's trajectories.\n",
    "        ## community argument is for indicating the community assignment\n",
    "        ## of the nodes if exists, if not pass along None.\n",
    "        ## edge_color\n",
    "        ## pv == pass a list of pv cell indices or None --dashes the pv cells\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        if edge_color == True: ed_color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(self.length)]\n",
    "        else: e_color = 'black' #[\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(self.length)]\n",
    "\n",
    "            \n",
    "        if community is None: node_color = 'r'     \n",
    "        else:\n",
    "            colors = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(int(np.max(community)))]\n",
    "            comap = mpl.colors.ListedColormap(colors)\n",
    "            node_color = community\n",
    "            norm = plt.Normalize(0,int(np.max(community)))\n",
    "\n",
    "        if node_id == None:\n",
    "            for k in self.nodes:\n",
    "                for j in range(1,self.length):\n",
    "                    for i in self.neighbors(k, j):\n",
    "                        if self.list_adjacency[j][k][i] > thresh:\n",
    "                            layers.append((j-1, j))\n",
    "                            layers.append((k, i))\n",
    "                            try: layers.append('%s' %ed_color[j])\n",
    "                            except: layers.append('%s'%e_color)\n",
    "                            \n",
    "            fig,ax = plt.subplots(1,1,figsize = (20,10))\n",
    "            plt.plot(*layers,figure = fig)\n",
    "            plt.title('Temporal trajectories of all the cells that are stronger than %f'%(thresh), fontsize = 20)\n",
    "            plt.xlabel('Layers',fontsize = 15)\n",
    "            plt.ylabel('Nodes',fontsize = 15)\n",
    "\n",
    "\n",
    "            for i in range(self.size):\n",
    "                x = np.linspace(0, self.length -1, self.length)\n",
    "                y = np.linspace(i,i, self.length)\n",
    "                try:plt.scatter(x, y, s = 15, c = node_color, figure = fig, alpha = 1)\n",
    "                except: plt.scatter(x, y, s = 15, c = node_color[i], norm = norm, figure = fig, alpha = 1, cmap = comap)\n",
    "\n",
    "\n",
    "        else:\n",
    "            for j in range(1,self.length):\n",
    "                for i in self.neighbors(node_id,j):\n",
    "                    if self.list_adjacency[j][node_id][i] > thresh:\n",
    "                        layers.append((j-1, j))\n",
    "                        layers.append((node_id, i))\n",
    "                        try: layers.append('%s' %ed_color[j])\n",
    "                        except: layers.append('%s'%e_color)\n",
    "                            \n",
    "            fig,ax = plt.subplots(1, 1, figsize = (20,10))\n",
    "            plt.plot(*layers, figure = fig)\n",
    "            plt.title('Temporal trajectories of the cell %d that are stronger than %f'%(node_id,thresh), fontsize = 20)\n",
    "            plt.xlabel('Layers', fontsize = 15)\n",
    "            plt.ylabel('Nodes', fontsize = 15)\n",
    "            \n",
    "            for i in range(self.size):\n",
    "                x = np.linspace(0, self.length-1, self.length)\n",
    "                y = np.linspace(i, i, self.length)\n",
    "                try:plt.scatter(x, y, s = 15, c = node_color, figure = fig, alpha = 1)\n",
    "                except: plt.scatter(x, y, s = 15, c = node_color[i], norm = norm, figure = fig, alpha = 1, cmap = comap)\n",
    "        \n",
    "        if community is not None:\n",
    "            cbar = plt.colorbar(cmap = cmap)\n",
    "        \n",
    "            cbar.set_ticks([i for i in np.arange(0,int(np.max(community)),3)])\n",
    "            cbar.set_ticklabels([i for i in np.arange(0,int(np.max(community)),3)])\n",
    "            cbar.set_label('Colorbar for node communities - total of %d communities'%int(np.max(community)), rotation = 270)\n",
    "        if pv is not None:\n",
    "            plt.hlines(pv, 0, self.length-1, color = 'b', alpha = 0.4, linestyle = 'dashed')\n",
    "            plt.yticks(pv, color = 'b')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        \n",
    "    def update_interlayer(self, spikes, X, omega_global, percentage, method):\n",
    "        \n",
    "        binned_spikes = self.bin_time_series(spikes, gaussian = False)\n",
    "        sp = np.nonzero(binned_spikes)\n",
    "        \n",
    "        layers ,num_neurons, t = self.length, self.size, self.windowsize\n",
    "        \n",
    "        count_spikes = np.zeros((layers, num_neurons))\n",
    "        interlayer = np.ones((layers-1, num_neurons))\n",
    "    \n",
    "        if method == 'local':\n",
    "            for i in range(len(sp[0])):\n",
    "                l, n, t = sp[0][i], sp[1][i], sp[2][i]\n",
    "                count_spikes[l][n] = count_spikes[l][n] + 1\n",
    "            interlayers = []\n",
    "            for i in range(layers-1):\n",
    "                zscores = zscore(np.diff(count_spikes, axis = 0)[i])\n",
    "                layerweights = []\n",
    "                for j in range(num_neurons):\n",
    "                    if zscores[j] <= X: layerweights.append(percentage*omega_global)\n",
    "                    else: layerweights.append(omega_global)\n",
    "                interlayers.append(layerweights)\n",
    "\n",
    "        elif method == 'global':\n",
    "            for i in range(len(sp[0])):\n",
    "                l, n, t = sp[0][i], sp[1][i], sp[2][i]\n",
    "                count_spikes[l][n] = count_spikes[l][n] + 1\n",
    "            interlayers = []\n",
    "            zscores = zscore(sum(np.diff(count_spikes, axis = 0)))\n",
    "            for i in range(layers-1):\n",
    "                layerweights = []\n",
    "                for j in range(num_neurons):\n",
    "                    if zscores[j] <= X: layerweights.append(percentage*omega_global)\n",
    "                    else: layerweights.append(omega_global)\n",
    "                interlayers.append(layerweights)\n",
    "    \n",
    "        #TODO:::  elif method == 'adjacent':\n",
    "    \n",
    "        return(interlayers)\n",
    "    \n",
    "    def community_consensus_iterative(self, C):\n",
    "        ## function finding the consensus of a given set of partitions. refer to the paper:\n",
    "        ## 'Robust detection of dynamic community structure in networks', Danielle S. Bassett, \n",
    "        ## Mason A. Porter, Nicholas F. Wymbs, Scott T. Grafton, Jean M. Carlson et al.\n",
    "        \n",
    "        \n",
    "        npart,m  = C.shape \n",
    "        C_rand3 = np.zeros((C.shape)) #permuted version of C\n",
    "        X = np.zeros((m,m)) #Nodal association matrix for C\n",
    "        X_rand3 = X # Random nodal association matrix for C_rand3\n",
    "\n",
    "        # randomly permute rows of C\n",
    "        for i in range(npart):\n",
    "            C_rand3[i,:] = C[i,np.random.permutation(m)]\n",
    "            for k in range(m):\n",
    "                for p in range(m):\n",
    "                    if int(C[i,k]) == int(C[i,p]): X[p,k] = X[p,k] + 1 #(i,j) is the # of times node i and j are assigned in the same comm\n",
    "                    if int(C_rand3[i,k]) == int(C_rand3[i,p]): X_rand3[p,k] = X_rand3[p,k] + 1 #(i,j) is the # of times node i and j are expected to be assigned in the same comm by chance\n",
    "        #thresholding\n",
    "        #keep only associated assignments that occur more often than expected in the random data\n",
    "\n",
    "        X_new3 = np.zeros((m,m))\n",
    "        X_new3[X>(np.max(np.triu(X_rand3,1)))/2] = X[X>(np.max(np.triu(X_rand3,1)))/2]\n",
    "        \n",
    "        ##turn thresholded nodal association matrix into igraph\n",
    "        edge_list = []\n",
    "        weight_list = []\n",
    "        for k,e in enumerate(np.transpose(np.nonzero(X_new3))):\n",
    "            i,j = e[0], e[1]\n",
    "            pair = (i,j)\n",
    "            edge_list.append(pair)\n",
    "            weight_list.append(X_new3[i][j])\n",
    "        \n",
    "        G = ig.Graph()\n",
    "        G.add_vertices(m)\n",
    "        G.add_edges(edge_list)\n",
    "        G.es['weight'] = weight_list\n",
    "        G.vs['id'] = list(range(m))\n",
    "        \n",
    "        optimiser = la.Optimiser()\n",
    "        partition = la.ModularityVertexPartition(G, weights = 'weight')\n",
    "        diff = optimiser.optimise_partition(partition, n_iterations = -1)\n",
    "        \n",
    "        return(partition)\n",
    "    \n",
    "    def run_community_detection(self, interlayers, resolutions, update = False, consensus = False, **kwargs):\n",
    "        \n",
    "        grid = len(interlayers)\n",
    "        membership_partitions = {}\n",
    "        parameter_plane = np.zeros((len(resolutions),len(interlayers)))\n",
    "        C = np.zeros((grid*grid, self.size*self.length))\n",
    "        for i,e in enumerate(interlayers):\n",
    "            membership_labels = []\n",
    "            igraphs = self.create_igraph()\n",
    "    \n",
    "            ##update interlayer edges\n",
    "            if update: inter_edge = self.update_interlayer(kwargs['spikes'], X = 0.5, omega_global = e, percentage = 0.01, method = kwargs['method'])    \n",
    "            else: inter_edge = e\n",
    "                \n",
    "            for j,f in enumerate(resolutions):\n",
    "                parts, inter_parts = self.leiden(igraphs, inter_edge, f)\n",
    "                C[i*grid+j,:] = inter_parts.membership\n",
    "                comm_labels, comm_size  = self.membership(inter_parts)\n",
    "                membership_labels.append(comm_labels)\n",
    "                parameter_plane[i][j] = comm_size\n",
    "            membership_partitions['interlayer %.2f'%e] = membership_labels\n",
    "            \n",
    "        if consensus: return(membership_partitions, self.membership(self.community_consensus_iterative(C)))\n",
    "        else: return(membership_partitions, parameter_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_corr(x,y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    \n",
    "    x_cov_std = np.nanmax(np.sqrt(np.correlate(x - x_mean, x - x_mean, 'full')))\n",
    "    y_cov_std = np.nanmax(np.sqrt(np.correlate(y - y_mean, y - y_mean, 'full')))\n",
    "\n",
    "    normalization = x_cov_std * y_cov_std\n",
    "        \n",
    "\n",
    "    unnormalized_correlation = np.correlate(x - x_mean, y - y_mean, 'full')\n",
    "    \n",
    "    corr_array = unnormalized_correlation/normalization\n",
    "\n",
    "    return(corr_array)\n",
    "\n",
    "def max_norm_cross_corr(x1, x2):\n",
    "    \n",
    "    correlation= normalized_cross_corr(x1, x2)\n",
    "    \n",
    "    lag = abs(correlation).argmax() - len(x1)+1\n",
    "    \n",
    "    max_corr = max(abs(correlation))\n",
    "    \n",
    "    return(max_corr, lag)\n",
    "\n",
    "def cross_correlation_matrix(data):\n",
    "    #input: n x t matrix where n is the number of rois and t is the duration of the time series\n",
    "    #return: n x n symmetric cross correlation matrix, nxn uppertriangular cross correlation matrix and lag matrix\n",
    "    n, t = data.shape\n",
    "    X = np.zeros((n,n))\n",
    "    lag = np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            X[i][j],lag[i][j] = max_norm_cross_corr(data[i,:],data[j,:])\n",
    "    X[np.isnan(X)] = 0\n",
    "    lag[np.isnan(lag)] = 0\n",
    "    \n",
    "    X_full = X + X.T\n",
    "    lag = lag + lag.T\n",
    "    return(X_full, X, lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_time_series(array, binsize, gaussian = True, **kwargs):\n",
    "        #input: nxt matrix \n",
    "        #returns: binned time series i.e. l x n x binsize\n",
    "        \n",
    "    n = array.shape[0] # number of neurons\n",
    "    totalsize = array.shape[1] # total duration of spikes\n",
    "    gauss_array = np.zeros((n,totalsize))\n",
    "    l = int(totalsize/binsize) # number of resulting layers\n",
    "        \n",
    "    if gaussian:\n",
    "        for i in range(n):\n",
    "            gauss_array[i] = gaussian_filter(array[i],kwargs['sigma'])\n",
    "    else: gauss_array = array\n",
    "            \n",
    "    A = np.zeros((l,n,binsize))\n",
    "    for i in range(l):\n",
    "        A[i] = gauss_array[:,i*binsize:(i+1)*binsize]\n",
    "    return(A)\n",
    "\n",
    "def binarize(array):\n",
    "    n,t = array.shape\n",
    "    binary_spikes = np.zeros((n,t))\n",
    "    for i in range(n):\n",
    "        for j in range(t):\n",
    "            if array[i][j] == 0: pass\n",
    "            else: binary_spikes[i][j] = 1\n",
    "    return(binary_spikes)\n",
    "\n",
    "def gaussian_filter(array,sigma):\n",
    "    #sigma=0.25==gaussian kernel with length 3\n",
    "    #sigma=0.5==gaussian kernel with length 5\n",
    "    #sigma=1==gaussian kernel with length 9\n",
    "    return(gaussian_filter1d(array,sigma))\n",
    "\n",
    "def jitter(spike, k):\n",
    "    #jittering the given spike train\n",
    "    jittered = np.zeros(spike.shape)\n",
    "    for i in np.nonzero(spike)[1]:\n",
    "        jitt = random.randint(-k,k)\n",
    "        try:jittered[0,i+jitt] = 1\n",
    "        except:jittered[0,i] = 1\n",
    "    return(jittered)\n",
    "\n",
    "\n",
    "def spike_count(spikes, ax, num_bins = None, t_min = None, t_max = None):\n",
    "    n,t = spikes.shape\n",
    "    if t_min is None: t_min = 0\n",
    "    if t_max is None: t_max = t\n",
    "    if t_max<=t_min: raise ValueError('t_min should be less than t_max')\n",
    "    spike_count = []\n",
    "    binary = binarize(spikes)\n",
    "    for i in range(n):\n",
    "        spike_count.append(np.sum(binary[i][t_min:t_max]))\n",
    "    if num_bins is None: num_bins = int(np.max(spike_count) - np.min(spike_count))\n",
    "    n, bins, patches = ax.hist(spike_count, num_bins, color = 'blue')\n",
    "    ax.set_title(\"Spike Rate Distribution\")\n",
    "    ax.set_xlabel(\"Total Number of Spikes\", fontsize = 22)\n",
    "    ax.set_ylabel(\"Number of Neurons\", fontsize = 22)\n",
    "    return(n,bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms = 6\n",
    "fixed_size = [int(abs(np.random.normal(30,10))) for i in range(comms)]\n",
    "path = '/projects/academic/smuldoon/bengieru/leiden/parameter_sweep/merge_gaussian_size/changing_spike_rate/'\n",
    "\n",
    "\n",
    "comm_sizes = [fixed_size, #layer1 community sizes\n",
    "              [fixed_size[0]+fixed_size[1]+fixed_size[2],fixed_size[3],fixed_size[4]+fixed_size[5]]] #layer2 community sizes\n",
    "spike_rate = [[int(abs(np.random.normal(20,8))) for i in range(comms)],#spikerates of the respective communities in layer5\n",
    "              [int(abs(np.random.normal(20,8))), int(abs(np.random.normal(20,8))), int(abs(np.random.normal(20,8)))]]#spikerates of the respective communities in layer6\n",
    "\n",
    "\n",
    "num_neurons = int(sum(comm_sizes[0]))\n",
    "bin_size = 1000.0 # in frames, in every bin_size, a community activity occurs\n",
    "seconds = len(spike_rate)\n",
    "total_duration = int(seconds*bin_size)\n",
    "window_size = 1000 # size, in frames, each adjacency matrix correspond to. better to be equal to bin_size \n",
    "standard_dev = 1.2 # for gaussian kernel\n",
    "k = 5 #for jittering the spikes\n",
    "layers = int(total_duration/window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = np.zeros((num_neurons, total_duration))\n",
    "for s in range(seconds):\n",
    "    neuron_count = 0\n",
    "    for i,e in enumerate(comm_sizes[s]):\n",
    "        initial_master = homogeneous_poisson_process(rate = spike_rate[s][i]*Hz, t_start = s*(bin_size)*ms, t_stop = (s+1)*bin_size*ms, as_array=True)\n",
    "        master_spikes = np.zeros((1,total_duration))\n",
    "    \n",
    "        for j,f in enumerate(initial_master):\n",
    "            master_spikes[0][int(f)] = 1\n",
    "\n",
    "        for j in range(e):\n",
    "            spikes[neuron_count+j][int(s*bin_size):int((s+1)*bin_size)] = jitter(master_spikes[:,int(s*bin_size):int((s+1)*bin_size)], k)\n",
    "        neuron_count = neuron_count + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(20,10))\n",
    "ax.imshow(spikes, origin = 'lower', interpolation='nearest', aspect='auto',  extent = [0,total_duration,0,num_neurons])\n",
    "ax.set_title('Spike Trains generated via Poisson Process for %d synthetic neurons'%num_neurons, fontsize = 30)\n",
    "ax.set_xlabel('TIME (in Miliseconds)', fontsize = 20)\n",
    "ax.set_xticks([j*1000 for j in range(int(total_duration/1000)+1)])\n",
    "ax.set_yticks([i*10 for i in range(int(num_neurons/10)+1)])\n",
    "ax.set_ylabel('Neuron ID', fontsize = 25)\n",
    "ax.set_xlabel('Time (Frames)', fontsize = 20)\n",
    "ax.tick_params(axis = 'both', labelsize = 20)\n",
    "plt.savefig(path+'spiketrain.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize= (10,10))\n",
    "n,bins = spike_count(spikes, ax)\n",
    "plt.savefig(path+'spike_distribution.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_spikes = bin_time_series(spikes, window_size, gaussian = True, sigma = standard_dev)\n",
    "fig,ax = plt.subplots(layers,1,figsize=(20,50))\n",
    "for i in range(layers):\n",
    "    ax[i].imshow(binned_spikes[i], origin = 'lower', interpolation='nearest', aspect='auto')\n",
    "    ax[i].set_title('Gaussian Spikes (Layer %d)'%(i+1), fontsize = 20)\n",
    "    ax[i].set_xlabel('TIME (in Miliseconds)', fontsize = 20)\n",
    "    ax[i].set_xticks([j*100 for j in range(11)])\n",
    "    ax[i].set_yticks([j*10 for j in range(int(num_neurons/10)+1)])\n",
    "    ax[i].set_ylabel('Neuron ID', fontsize = 25)\n",
    "    ax[i].set_xlabel('Time (Frames)', fontsize = 20)\n",
    "    ax[i].tick_params(axis = 'both', labelsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path+'binned_spiketrain.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create cross-correlation matrices that are the adjacency matrices of the network at each layer\n",
    "adjacency_matrices = []\n",
    "for i in range(layers):\n",
    "    adjacency_matrices.append(cross_correlation_matrix(binned_spikes[i])[0])\n",
    "\n",
    "padded_adjacencies = [adjacency_matrices[0]]  + adjacency_matrices + [adjacency_matrices[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(layers, layers, figsize = (32,32))\n",
    "for i in range(layers):\n",
    "    for j in range(layers):\n",
    "        k = ax[i][j].imshow(padded_adjacencies[i*2+j], \n",
    "                            origin = 'lower', \n",
    "                            interpolation='nearest', \n",
    "                            aspect='auto',  \n",
    "                            extent = [0,num_neurons,0,num_neurons])\n",
    "        ax[i][j].set_title('Adjacency Matrix (Layer %d)'%(i*2+j +1), fontsize = 35)\n",
    "        ax[i][j].set_xticks([k*10 for k in range(int(num_neurons/10)+1)])\n",
    "        ax[i][j].set_yticks([k*10 for k in range(int(num_neurons/10)+1)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 20)\n",
    "fig.suptitle('Community merge with sizes %d,%d,%d,%d,%d,%d and spike rates %d,%d,%d,%d,%d,%d for 1st layer and %d,%d,%d for 2nd layer'%(comm_sizes[0][0],comm_sizes[0][1],comm_sizes[0][2],comm_sizes[0][3],comm_sizes[0][4],comm_sizes[0][5],spike_rate[0][0],spike_rate[0][1],spike_rate[0][2],spike_rate[0][3],spike_rate[0][4],spike_rate[0][5],spike_rate[1][0],spike_rate[1][1],spike_rate[1][2]), fontsize = 45)\n",
    "cbar = fig.colorbar(k, ax = ax.flat, orientation = 'horizontal')\n",
    "cbar.ax.tick_params(labelsize = 25) \n",
    "plt.savefig(path+'adjacency.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = temporal_network(num_neurons, \n",
    "                      layers+2, \n",
    "                      window_size, \n",
    "                      data = 'list__adjacency', \n",
    "                      list_adjacency = padded_adjacencies, \n",
    "                      omega = 1, \n",
    "                      kind = 'ordinal')\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize = (25,15))\n",
    "TN.raster_plot(spikes, ax)\n",
    "plt.savefig(path+'raster_plot.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 50\n",
    "index = 10\n",
    "resolutions = np.linspace(0, 1.25, grid)\n",
    "interlayers = np.linspace(0, 1, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "membership_partitions, parameter_plane = TN.run_community_detection(interlayers, resolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i]][j], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i],resolutions[j]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+index]][j], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+index],resolutions[j]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+2*index]][j], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+2*index],resolutions[j]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+3*index]][j], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+3*index],resolutions[j]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+4*index]][j], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+4*index],resolutions[j]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index, index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i]][j+index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i],resolutions[j+index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities6.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+index]][j+index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+index],resolutions[j+index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities7.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+index]][j+index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+2*index],resolutions[j+index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities8.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+3*index]][j+index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+3*index],resolutions[j+index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities9.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+4*index]][j+index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+4*index],resolutions[j+index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities10.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i]][j+2*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i],resolutions[j+2*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities11.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+index]][j+2*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+index],resolutions[j+2*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities12.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+2*index]][j+2*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+2*index],resolutions[j+2*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities13.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+3*index]][j+2*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+3*index],resolutions[j+2*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities14.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+4*index]][j+2*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+4*index],resolutions[j+2*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities15.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (10*index+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i]][j+3*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i],resolutions[j+3*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities16.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+index]][j+3*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+index],resolutions[j+3*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities17.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+2*index]][j+3*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+2*index],resolutions[j+3*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities18.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+3*index]][j+3*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+3*index],resolutions[j+3*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities19.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+4*index]][j+3*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+4*index],resolutions[j+3*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities20.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i]][j+4*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i],resolutions[j+4*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities21.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+index]][j+4*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+index],resolutions[j+4*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities22.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+2*index]][j+4*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+2*index],resolutions[j+4*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities23.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (index*10+5,index*10))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+3*index]][j+4*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+3*index],resolutions[j+4*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities24.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(index,index, figsize = (10*index+5,10*index))\n",
    "for i in range(index):\n",
    "    for j in range(index):\n",
    "        comms, c = TN.community(membership_partitions['interlayer %.2f'%interlayers[i+4*index]][j+4*index], ax[i][j])\n",
    "        ax[i][j].set_xticks([i for i in range(layers)])\n",
    "        ax[i][j].set_yticks([i*10 for i in range(13)])\n",
    "        ax[i][j].tick_params(axis = 'both', labelsize = 25)\n",
    "        ax[i][j].set_xlabel('Layers (Time)', fontsize = 28)\n",
    "        ax[i][j].set_ylabel('Neuron ID', fontsize = 28)\n",
    "        ax[i][j].set_title('%d Communities, interlayer: %.2f, reso:%.2f'%(len(c),interlayers[i+4*index],resolutions[j+4*index]), fontsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(path + 'communities25.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
