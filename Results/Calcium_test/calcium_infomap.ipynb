{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bengieru/MLN/Results/Calcium_test/Temporal_Community_Detection.py:29: UserWarning: Graph-tool requires its own environment. Restart the kernel with a gt environment to run DSBM, otherwise you can proceed.\n",
      "  warnings.warn(message = 'Graph-tool requires its own environment. Restart the kernel with a gt environment to run DSBM, otherwise you can proceed.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Temporal_Community_Detection import temporal_network\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from math import floor\n",
    "import random\n",
    "import csv\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9 , 0.95, 1.  , 1.05, 1.1 , 1.15, 1.2 , 1.25, 1.3 ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.9,1.3,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_firing(spikes, thresh, pv):\n",
    "    n,t = spikes.shape\n",
    "    indices = []\n",
    "    for i in range(n):\n",
    "        if len(np.nonzero(spikes[i])[0]) >= thresh:\n",
    "            indices.append(i)\n",
    "    removed_spikes = np.zeros((len(indices),t))\n",
    "    for i,e in enumerate(indices):\n",
    "        removed_spikes[i] = spikes[e]\n",
    "    removed_neurons = list(set([i for i in range(n)])-set(indices))\n",
    "    \n",
    "    ##update pv indices\n",
    "    new_pvs = np.array(sorted(pv))\n",
    "    for i,e in enumerate(sorted(removed_neurons)):\n",
    "        new_pvs = np.append(new_pvs[new_pvs<e],new_pvs[new_pvs>e]-1, axis = 0)\n",
    "    list(new_pvs)\n",
    "    return(removed_spikes, removed_neurons, new_pvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/projects/academic/smuldoon/bengieru/Community_Detection/calcium_data_test/' ## base path\n",
    "output = 'Johan_Clean_Traces_Features_and_Spikes/' #spikes and traces file\n",
    "roi = 'sarah_ROI/' #roi file\n",
    "subjects = load_obj(path + 'subjects/', 'subjects')\n",
    "epochs = ['_baseline', '_early', '_pre']\n",
    "trackable = [subjects['wt'][3], subjects['het'][6], subjects['het'][8], subjects['het'][13], subjects['het'][4], subjects['het'][3], subjects['het'][2]]\n",
    "\n",
    "pvs = {}\n",
    "pvs['%s'%trackable[0]] = load_obj(path +'subjects/','pv_wt')['%s'%trackable[0]]\n",
    "for i in range(1,len(trackable)):\n",
    "    temp = load_obj(path +'subjects/','pv_het')['%s'%trackable[i]]\n",
    "    pvs['%s'%trackable[i]] = (np.array(temp)-1).tolist() ##adjust python indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 2000 ## binning the time into chunks of\n",
    "layers = int(8000/time) ## number of layers\n",
    "spikes_trackable = {}\n",
    "num_rois_trackable = {}\n",
    "for i,e in enumerate(trackable):\n",
    "    for j,f in enumerate(epochs):\n",
    "        spikes_trackable['%s'%(e+f)] = read_csv(path, output, e+f, roi)\n",
    "        num_rois_trackable['%s'%(e+f)] = read_roi(path, roi, e+f) ## number of rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_spikes_trackable ={}\n",
    "#remove non-firing\n",
    "for i,e in enumerate(trackable):\n",
    "    for j,f in enumerate(epochs):\n",
    "        spikes_trackable, removed_neurons, new_pvs = remove_non_firing(spikes_trackable['%s'%(e+f)], 5 ,pvs['%s'%e][0])\n",
    "        path_nbr_update = path + 'infomap/neighborhood_update/%s/'%(e)\n",
    "        os.makedirs(path_nbr_update, exist_ok = True)\n",
    "        with open(path_nbr_update + \"firing_spikes_%s.pkl\"%(e+f), \"wb\") as fp:\n",
    "                pickle.dump(new_spikes_trackable, fp)\n",
    "        with open(path_nbr_update + \"adjusted_pvs_%s.pkl\"%(e+f), \"wb\") as fp:\n",
    "                pickle.dump(new_pvs, fp)\n",
    "        with open(path_nbr_update + \"removed_neurons_%s.pkl\"%(e+f), \"wb\") as fp:\n",
    "                pickle.dump(removed_neurons, fp)\n",
    "        new_spikes_trackable['%s'%(e+f)] = spikes_trackable\n",
    "        num_rois_trackable['%s'%(e+f)] = int(num_rois_trackable['%s'%(e+f)] - len(removed_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_binary_spikes_trackable = {}\n",
    "for i,e in enumerate(trackable):\n",
    "    path_nbr_update = path + 'infomap/neighborhood_update/%s/'%(e)\n",
    "    for j,f in enumerate(epochs):\n",
    "        # bin the spikes into fixed length and apply gaussian kernel of length 9\n",
    "        binary_trackable = binarize(new_spikes_trackable['%s'%(e+f)])\n",
    "        binned_binary_spikes_trackable['%s'%(e+f)] = bin_time_series(binary_trackable, \n",
    "                                                                     time, \n",
    "                                                                     gaussian = True, \n",
    "                                                                     sigma = 1.25)\n",
    "        \n",
    "        with open(path_nbr_update + \"binary_spikes_%s.pkl\"%(e+f), \"wb\") as fp:\n",
    "            pickle.dump(binary_trackable, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrices = {}\n",
    "for i,e in enumerate(trackable):\n",
    "    path_nbr_update = path + 'infomap/neighborhood_update/%s/'%(e)\n",
    "    for j,f in enumerate(epochs):  \n",
    "        adjacencies = []\n",
    "        for k in range(layers):\n",
    "            adjacencies.append(cross_correlation_matrix(binned_binary_spikes_trackable['%s'%(e+f)][k])[0])\n",
    "        adjacency_matrices['%s'%(e+f)] = adjacencies\n",
    "        \n",
    "        fig,ax = plt.subplots(1,4, figsize = (60,20))\n",
    "        for i in range(4):\n",
    "            k = ax[i].imshow(adjacency_matrices['%s'%(e+f)][i], \n",
    "                             origin = 'lower', \n",
    "                             interpolation = 'nearest', \n",
    "                             aspect='auto',  \n",
    "                             extent = [0,num_rois_trackable['%s'%(e+f)],0,num_rois_trackable['%s'%(e+f)]])\n",
    "            ax[i].set_title('Adjacency Matrix (Layer %d)'%(i +1), fontsize = 30)\n",
    "            ax[i].set_xticks([k*10 for k in range(int(num_rois_trackable['%s'%(e+f)]/10)+1)])\n",
    "            ax[i].set_yticks([k*10 for k in range(int(num_rois_trackable['%s'%(e+f)]/10)+1)])\n",
    "            ax[i].tick_params(axis = 'both', labelsize = 25)\n",
    "        cbar = fig.colorbar(k, ax = ax.flat, orientation = 'horizontal')\n",
    "        cbar.ax.tick_params(labelsize = 30) \n",
    "        plt.savefig(path_nbr_update + 'adjacencies_%s.pdf'%(e+f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TNs = {}\n",
    "for i,e in enumerate(trackable):\n",
    "    for j,f in enumerate(epochs): \n",
    "        TNs['%s'%(e+f)] = temporal_network(num_rois_trackable['%s'%(e+f)], \n",
    "                                    layers, \n",
    "                                    time, \n",
    "                                    data = 'list__adjacency', \n",
    "                                    list_adjacency = adjacency_matrices['%s'%(e+f)], \n",
    "                                    omega = 1, \n",
    "                                    kind = 'ordinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshs = np.linspace(0.1, 0.5, 9)\n",
    "inters = np.linspace(0, 0.8, 9)\n",
    "for i,e in enumerate(trackable):\n",
    "    path_nbr_update = path + 'infomap/neighborhood_update/%s/'%(e)\n",
    "    for j,f in enumerate(epochs):\n",
    "        membership_nbr_update, labels_nbr_update = TNs['%s'%(e+f)].run_community_detection('infomap', \n",
    "                                                                                           update_method = 'neighborhood', \n",
    "                                                                                           interlayers = inters, \n",
    "                                                                                           thresholds = threshs)\n",
    "        with open(path_nbr_update + \"labels_%s.pkl\"%(e+f), \"wb\") as fp:\n",
    "            pickle.dump(labels_nbr_update, fp)\n",
    "        \n",
    "        with open(path_nbr_update + \"membership_%s.pkl\"%(e+f), \"wb\") as fp:\n",
    "            pickle.dump(membership_nbr_update, fp)\n",
    "            \n",
    "        fig,ax = plt.subplots(9,9, figsize = (9*15+5,9*15))\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                comms, c = TNs['%s'%(e+f)].community(membership_nbr_update['interlayer=%.3f'%inters[i]][j], ax[i][j])\n",
    "                ax[i][j].set_xticks([i for i in range(layers)])\n",
    "                ax[i][j].set_yticks([i*10 for i in range(int(num_rois_trackable['%s'%(e+f)]/10)+1)])\n",
    "                ax[i][j].tick_params(axis = 'both', labelsize = 12)\n",
    "                ax[i][j].set_xlabel('Layers (Time)', fontsize = 25)\n",
    "                ax[i][j].set_ylabel('Neuron ID', fontsize = 25)\n",
    "                ax[i][j].set_title('%d Communities, interlayer:%.3f, threshold:%.3f'%(len(c),inters[i],threshs[j]), fontsize=29)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path_nbr_update + 'communities_%s.pdf'%(e+f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
